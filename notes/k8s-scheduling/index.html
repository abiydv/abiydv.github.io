<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>K8s Scheduling | @abiydv</title>
<meta name=keywords content><meta name=description content="Which pod goes where?
How does it help? Opportunities for cost saving by utilizing better scheduling. snorkel ai case-study Restrict workloads to specific nodes. Ex - run gpu workloads on gpu nodes, or don&rsquo;t run cpu-only workloads on gpu nodes. Some users want to put multiple pods that communicate with one another in the same zone to avoid inter-zone traffic charges [[aws-well-architected#AZ Affinity]]
Anti-affinity is useful to spread pods across failure domains/topology (AZ or Region)"><meta name=author content><link rel=canonical href=https://abiydv.github.io/notes/k8s-scheduling/><link crossorigin=anonymous href=/assets/css/stylesheet.c5edd088d0c984c192170cfbab7d2de030010ee0b7d771bd6bca049dd2332874.css integrity="sha256-xe3QiNDJhMGSFwz7q30t4DABDuC313G9a8oEndIzKHQ=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://abiydv.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://abiydv.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://abiydv.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://abiydv.github.io/apple-touch-icon.png><link rel=mask-icon href=https://abiydv.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://abiydv.github.io/notes/k8s-scheduling/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="K8s Scheduling"><meta property="og:description" content="Which pod goes where?
How does it help? Opportunities for cost saving by utilizing better scheduling. snorkel ai case-study Restrict workloads to specific nodes. Ex - run gpu workloads on gpu nodes, or don&rsquo;t run cpu-only workloads on gpu nodes. Some users want to put multiple pods that communicate with one another in the same zone to avoid inter-zone traffic charges [[aws-well-architected#AZ Affinity]]
Anti-affinity is useful to spread pods across failure domains/topology (AZ or Region)"><meta property="og:type" content="article"><meta property="og:url" content="https://abiydv.github.io/notes/k8s-scheduling/"><meta property="article:section" content="notes"><meta property="article:published_time" content="2024-04-16T00:00:00+00:00"><meta property="article:modified_time" content="2025-04-04T12:48:24+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="K8s Scheduling"><meta name=twitter:description content="Which pod goes where?
How does it help? Opportunities for cost saving by utilizing better scheduling. snorkel ai case-study Restrict workloads to specific nodes. Ex - run gpu workloads on gpu nodes, or don&rsquo;t run cpu-only workloads on gpu nodes. Some users want to put multiple pods that communicate with one another in the same zone to avoid inter-zone traffic charges [[aws-well-architected#AZ Affinity]]
Anti-affinity is useful to spread pods across failure domains/topology (AZ or Region)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Notes","item":"https://abiydv.github.io/notes/"},{"@type":"ListItem","position":2,"name":"K8s Scheduling","item":"https://abiydv.github.io/notes/k8s-scheduling/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"K8s Scheduling","name":"K8s Scheduling","description":"Which pod goes where?\nHow does it help? Opportunities for cost saving by utilizing better scheduling. snorkel ai case-study Restrict workloads to specific nodes. Ex - run gpu workloads on gpu nodes, or don\u0026rsquo;t run cpu-only workloads on gpu nodes. Some users want to put multiple pods that communicate with one another in the same zone to avoid inter-zone traffic charges [[aws-well-architected#AZ Affinity]]\nAnti-affinity is useful to spread pods across failure domains/topology (AZ or Region)","keywords":[],"articleBody":"Which pod goes where?\nHow does it help? Opportunities for cost saving by utilizing better scheduling. snorkel ai case-study Restrict workloads to specific nodes. Ex - run gpu workloads on gpu nodes, or don’t run cpu-only workloads on gpu nodes. Some users want to put multiple pods that communicate with one another in the same zone to avoid inter-zone traffic charges [[aws-well-architected#AZ Affinity]]\nAnti-affinity is useful to spread pods across failure domains/topology (AZ or Region)\nWhat is a Scheduler? profiles Summary Scheduling Depends On Reference nodeName node name nodeAffinity node label nodeaffinity nodeAntiAffinity node label podAffinity pod label, node label (topology key) podaffinity podAntiAffinity pod label, node label (topology key) There are a few options to control the scheduling of pods on specific nodes described below, starting with the simplest one.\nNode Name Schedule a pod to a specific node, no questions asked. Scheduler assumes resource requirements are met. If NO node with the specified nodeName exists, the pod is NOT scheduled, might even be deleted If the named node does not have enough resources, pod fails with errors like OutOfMemory In cloud environments, nodeName is likely to be dynamic and not fixed Useful for Custom [[#What is a Scheduler?|scheduler]] or If you need to bypass any configured schedulers Property spec: nodeName: kube01 Node Selector Simplest way to control the scheduling of a pod. Add property spec/nodeSelector to the pod configuration, and specify an existing node label Can also be used to restrict use of nodes, so new workloads are not deployed to it kubelet can apply labels to nodes Be careful when using labels to restrict nodes, the node’s kubelet shouldn’t be able to apply/update the label on itself Use node restriction plugin to control this node restriction better, uses label node-restriction.kubernetes.io/ Property spec: nodeSelector: matchExpressions: - key: string operator: In, NotIn, Exist, DoesNotExist, Gt, Lt values: [string] # array is replaced during strategic merge matchFields: - key: string operator: In, NotIn, Exist, DoesNotExist, Gt, Lt values: [string] # array is replaced during strategic merge matchExpressions or matchFields statements are treated as AND statements\nkubectl explain pod.spec.affinity.nodeAffinity\nKIND: Pod VERSION: v1 FIELD: nodeAffinity DESCRIPTION: Describes node affinity scheduling rules for the pod. Node affinity is a group of node affinity scheduling rules. FIELDS: preferredDuringSchedulingIgnoredDuringExecution \u003c[]PreferredSchedulingTerm\u003e The scheduler will prefer to schedule pods to nodes that satisfy the affinity expressions specified by this field, but it may choose a node that violates one or more of the expressions. The node that is most preferred is the one with the greatest sum of weights, i.e. for each node that meets all of the scheduling requirements (resource request, requiredDuringScheduling affinity expressions, etc.), compute a sum by iterating through the elements of this field and adding \"weight\" to the sum if the node matches the corresponding matchExpressions; the node(s) with the highest sum are the most preferred. requiredDuringSchedulingIgnoredDuringExecution If the affinity requirements specified by this field are not met at scheduling time, the pod will not be scheduled onto the node. If the affinity requirements specified by this field cease to be met at some point during pod execution (e.g. due to an update), the system may or may not try to eventually evict the pod from its node. #todo test this AND/OR condition\nExample #todo test if this actually works :D\napiVersion: v1 kind: Pod metadata: name: nginx labels: env: test spec: containers: - name: nginx image: nginx imagePullPolicy: IfNotPresent nodeSelector: matchFields: - key: disktype operator: In values: [ssd] Node Affinity Use node labels to schedule pods on preferred nodes.\nProperty kubernetes-api/v1.24/#affinity-v1-core\nspec: affinity: nodeAffinity: podAffinity: podAntiAffinity: RDS-IDE ^^ Easier to remember version of requiredDuringSchedulingIgnoredDuringExecution. Type of [[#Node Affinity]].\nLabel specified under this property must be present on the node during scheduling. If it’s subsequently removed, the pod still continues to run.\nScheduler will try to find a node that meets the expression. If no matching node is found, pod is NOT scheduled on any other node.\nIf the expression turns to false while the pod is running, it is still allowed to complete the execution.\nProperty spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - nodeSelectorTerm1 # same as spec.nodeSelector - nodeSelectorTerm2 Multiple nodeSelectorTerm can be specified, they are treated as OR statements\nPDS-IDE ^^ Easier to remember version of preferredDuringSchedulingIgnoredDuringExecution. Type of [[#Node Affinity]]\n[[#What is a Scheduler?|Scheduler]] will try to find a node that meets the expression, and has maximum aggregate weight. If no matching node is found, it still schedules the pod on a node.\nIf the expression turns to false while the pod is running, it is still allowed to complete the execution.\nProperty spec: affinity: nodeAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 0-100 preference: nodeSelectorTerm # same as spec.nodeSelector\tNode Anti-Affinity There is NO dedicated configuration field for this. Node anti-affinity is achieved by inverting the node affinity by using negation operators like NotIn, DoesNotExist in the specified nodeSelectorTerm\nPod Affinity Use running pod labels to schedule pods on preferred nodes. Like, deploy mysql pods on which ever nodes has postgresql pods running.\nThis is non-symmetric - no need to check if existing pods have specified any pod affinity before scheduling pods next to them that do specify a pod affinity\nalgorithm used by podaffinity\nProperty kubernetes-api/v1.24/#affinity-v1-core\nspec: affinity: nodeAffinity: podAffinity: podAntiAffinity: #todo What’s the difference between pod affinity and node affinity? #todo What happens if all pods are deployed with a ‘hard’ pod affinity, RDS-IDE?\nRDS-IDE ^^ Easier to remember version of requiredDuringSchedulingIgnoredDuringExecution. Type of [[#Pod Affinity]].\nLabel specified under this property must be present during scheduling. If it’s subsequently removed, the pod still continues to run.\n[[#What is a Scheduler?|Scheduler]] will try to find a node that meets the expression. If NO matching node is found, pod is NOT scheduled on any other node.\nIf the expression turns to false while the pod is running, it is still allowed to complete the execution.\nProperty spec: affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: # label query over pods matchExpressions: - key: string operator: In, NotIn, Exist, DoesNotExist, Gt, Lt values: [string] # array is replaced during strategic merge matchLabels: key: value namespaces: string namespaceSelector: matchExpressions: - key: string operator: In, NotIn, Exist, DoesNotExist, Gt, Lt values: [string] # array is replaced during strategic merge matchLabels: key: value topologyKey: string Multiple nodeSelectorTerm can be specified, they are treated as OR statements\ntopologyKey is the key of a node label. It is used to select nodes belonging to a particular topology domain. For ex - Only launch pods in a specific AZ for access to a required volume. Or, only launch pods in a specific region.\nPDS-IDE ^^ Easier to remember version of preferredDuringSchedulingIgnoredDuringExecution. Type of [[#Pod Affinity]].\n[[#What is a Scheduler?|Scheduler]] will try to find a node that meets the expression, and has maximum aggregate weight. If NO matching node is found, it still schedules the pod on a node.\nIf the expression turns to false while the pod is running, it is still allowed to complete the execution.\nProperty spec: affinity: podAffinity: preferredDuringSchedulingIgnoredDuringExecution: - weight: 0-100 podAffinityTerm: labelSelector: # label query over pods matchExpressions: - key: string operator: In, NotIn, Exist, DoesNotExist, Gt, Lt values: [string] # array is replaced during strategic merge matchLabels: key: value namespaces: string namespaceSelector: matchExpressions: - key: string operator: In, NotIn, Exist, DoesNotExist, Gt, Lt values: [string] # array is replaced during strategic merge matchLabels: key: value topologyKey: string\tWarning! labelSelector: null can cause NO pods to match the expression, and make a pod unschedulable!\nPod Anti-Affinity There is no dedicated configuration field for this. Pod anti-affinity is achieved by inverting the pod affinity by using negation operators like NotIn, DoesNotExist in the specified podAffinityTerm\nThis is symmetric - even if a pod doesn’t specify an anti-affinity rule, it is still checked so as not to violate the anti-affinity rule specified by an already running pod.\nTaints and Tolerations taint-and-toleration Autoscaling Karpenter https://karpenter.sh\nKarpenter consolidation policies - “whenempty” Pod Disruption Budgets Karpenter can switch instance types to rightsize the nodes if pods aren’t using the node’s resources - depends on consolidation policies Karpenter AZ awarness - How does it work with EBS across different AZ? aws blogs/volume topolog -awareness Karpenter can sometimes overestimate node sizes (daemonset overheads) - karpenter/issues/715 Cluster Auto-scaler cluster-autoscaling cluster-autoscaler Horizontal Pod Autoscaler HPA Vertical Pod Autoscaler VPA Event-driven Autoscaling KEDA References ","wordCount":"1379","inLanguage":"en","datePublished":"2024-04-16T00:00:00Z","dateModified":"2025-04-04T12:48:24+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://abiydv.github.io/notes/k8s-scheduling/"},"publisher":{"@type":"Organization","name":"@abiydv","logo":{"@type":"ImageObject","url":"https://abiydv.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://abiydv.github.io/ accesskey=h title="@abiydv (Alt + H)">@abiydv</a><div class=logo-switches></div></div><ul id=menu><li><a href=https://abiydv.github.io/ title=Home><span>Home</span></a></li><li><a href=https://abiydv.github.io/about/ title=About><span>About</span></a></li><li><a href=https://abiydv.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://abiydv.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://abiydv.github.io/notes/ title=Notes><span>Notes</span></a></li><li><a href=https://abiydv.github.io/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://abiydv.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://abiydv.github.io/notes/>Notes</a></div><h1 class=post-title>K8s Scheduling<sup>&nbsp;<span class="entry-stage incubating">&nbsp;incubating&nbsp;</span></sup></h1><div class=post-meta><s>16.4.24</s>&nbsp;4.4.25 / Notes / 7 min</div></header><div class=post-content><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#how-does-it-help aria-label="How does it help?">How does it help?</a></li><li><a href=#what-is-a-scheduler aria-label="What is a Scheduler?">What is a Scheduler?</a><ul><li><a href=#summary aria-label=Summary>Summary</a></li></ul></li><li><a href=#node-name aria-label="Node Name">Node Name</a><ul><li><a href=#property aria-label=Property>Property</a></li></ul></li><li><a href=#node-selector aria-label="Node Selector">Node Selector</a><ul><li><a href=#property-1 aria-label=Property>Property</a></li><li><a href=#example aria-label=Example>Example</a></li></ul></li><li><a href=#node-affinity aria-label="Node Affinity">Node Affinity</a><ul><li><a href=#property-2 aria-label=Property>Property</a></li><li><a href=#rds-ide aria-label=RDS-IDE>RDS-IDE</a><ul><li><a href=#property-3 aria-label=Property>Property</a></li></ul></li><li><a href=#pds-ide aria-label=PDS-IDE>PDS-IDE</a><ul><li><a href=#property-4 aria-label=Property>Property</a></li></ul></li></ul></li><li><a href=#node-anti-affinity aria-label="Node Anti-Affinity">Node Anti-Affinity</a></li><li><a href=#pod-affinity aria-label="Pod Affinity">Pod Affinity</a><ul><li><a href=#property-5 aria-label=Property>Property</a></li><li><a href=#rds-ide-1 aria-label=RDS-IDE>RDS-IDE</a><ul><li><a href=#property-6 aria-label=Property>Property</a></li></ul></li><li><a href=#pds-ide-1 aria-label=PDS-IDE>PDS-IDE</a><ul><li><a href=#property-7 aria-label=Property>Property</a><ul><li><a href=#warning aria-label=Warning!>Warning!</a></li></ul></li></ul></li></ul></li><li><a href=#pod-anti-affinity aria-label="Pod Anti-Affinity">Pod Anti-Affinity</a></li><li><a href=#taints-and-tolerations aria-label="Taints and Tolerations">Taints and Tolerations</a></li><li><a href=#autoscaling aria-label=Autoscaling>Autoscaling</a><ul><li><a href=#karpenter aria-label=Karpenter>Karpenter</a></li><li><a href=#cluster-auto-scaler aria-label="Cluster Auto-scaler">Cluster Auto-scaler</a></li><li><a href=#horizontal-pod-autoscaler aria-label="Horizontal Pod Autoscaler">Horizontal Pod Autoscaler</a></li><li><a href=#vertical-pod-autoscaler aria-label="Vertical Pod Autoscaler">Vertical Pod Autoscaler</a></li><li><a href=#event-driven-autoscaling aria-label="Event-driven Autoscaling">Event-driven Autoscaling</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div></div><div class=post-content><p><em>Which pod goes where?</em></p><h2 id=how-does-it-help>How does it help?<a hidden class=anchor aria-hidden=true href=#how-does-it-help>#</a></h2><ul><li>Opportunities for cost saving by utilizing better scheduling. <a href=https://aws.amazon.com/blogs/startups/how-snorkel-ai-achieved-over-40-cost-savings-by-scaling-machine-learning-workloads-using-amazon-eks/>snorkel ai case-study</a></li><li>Restrict workloads to specific nodes. Ex - run gpu workloads on gpu nodes, or don&rsquo;t run cpu-only workloads on gpu nodes.</li></ul><p>Some users want to put multiple pods that communicate with one another in the same zone to avoid inter-zone traffic charges [[aws-well-architected#AZ Affinity]]</p><p>Anti-affinity is useful to spread pods across failure domains/topology (AZ or Region)</p><h2 id=what-is-a-scheduler>What is a Scheduler?<a hidden class=anchor aria-hidden=true href=#what-is-a-scheduler>#</a></h2><ul><li><a href=https://kubernetes.io/docs/reference/scheduling/config/#profiles>profiles</a></li></ul><h3 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h3><table><thead><tr><th>Scheduling</th><th>Depends On</th><th>Reference</th></tr></thead><tbody><tr><td>nodeName</td><td>node name</td><td></td></tr><tr><td>nodeAffinity</td><td>node label</td><td><a href=https://github.com/kubernetes/kubernetes/blob/release-1.2/docs/design/nodeaffinity.md>nodeaffinity</a></td></tr><tr><td>nodeAntiAffinity</td><td>node label</td><td></td></tr><tr><td>podAffinity</td><td>pod label, node label (topology key)</td><td><a href=https://github.com/kubernetes/kubernetes/blob/release-1.2/docs/design/podaffinity.md>podaffinity</a></td></tr><tr><td>podAntiAffinity</td><td>pod label, node label (topology key)</td><td></td></tr></tbody></table><p>There are a few options to control the scheduling of pods on specific nodes described below, starting with the simplest one.</p><h2 id=node-name>Node Name<a hidden class=anchor aria-hidden=true href=#node-name>#</a></h2><ul><li>Schedule a pod to a specific node, no questions asked. Scheduler assumes resource requirements are met.</li><li>If <em>NO</em> node with the specified nodeName exists, the pod is <em>NOT</em> scheduled, might even be deleted</li><li>If the named node does not have enough resources, pod fails with errors like <code>OutOfMemory</code></li><li>In cloud environments, <code>nodeName</code> is likely to be dynamic and not fixed</li><li>Useful for<ul><li>Custom [[#What is a Scheduler?|scheduler]] or</li><li>If you need to <em>bypass</em> any configured schedulers</li></ul></li></ul><h3 id=property>Property<a hidden class=anchor aria-hidden=true href=#property>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodeName</span>: <span style=color:#ae81ff>kube01</span>
</span></span></code></pre></div><h2 id=node-selector>Node Selector<a hidden class=anchor aria-hidden=true href=#node-selector>#</a></h2><ul><li>Simplest way to control the scheduling of a pod.</li><li>Add property <code>spec/nodeSelector</code> to the pod configuration, and specify an existing node label</li><li>Can also be used to <em>restrict</em> use of nodes, so new workloads are not deployed to it<ul><li><code>kubelet</code> can apply labels to nodes</li><li>Be careful when using labels to <em>restrict</em> nodes, the node&rsquo;s <code>kubelet</code> shouldn&rsquo;t be able to apply/update the label on itself</li><li>Use <a href=https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#noderestriction>node restriction plugin</a> to control this node restriction better, uses label <code>node-restriction.kubernetes.io/</code></li></ul></li></ul><h3 id=property-1>Property<a hidden class=anchor aria-hidden=true href=#property-1>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodeSelector</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>	  - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>	    <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In, NotIn, Exist, DoesNotExist, Gt, Lt</span>
</span></span><span style=display:flex><span>	    <span style=color:#f92672>values</span>: [<span style=color:#ae81ff>string]</span> <span style=color:#75715e># array is replaced during strategic merge</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>matchFields</span>:
</span></span><span style=display:flex><span>	  - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>	    <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In, NotIn, Exist, DoesNotExist, Gt, Lt</span>
</span></span><span style=display:flex><span>	    <span style=color:#f92672>values</span>: [<span style=color:#ae81ff>string]</span> <span style=color:#75715e># array is replaced during strategic merge</span>
</span></span></code></pre></div><p><em>matchExpressions</em> or <em>matchFields</em> statements are treated as <em>AND</em> statements</p><p><code>kubectl explain pod.spec.affinity.nodeAffinity</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>KIND:       Pod
</span></span><span style=display:flex><span>VERSION:    v1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>FIELD: nodeAffinity &lt;NodeAffinity&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>DESCRIPTION:
</span></span><span style=display:flex><span>    Describes node affinity scheduling rules <span style=color:#66d9ef>for</span> the pod.
</span></span><span style=display:flex><span>    Node affinity is a group of node affinity scheduling rules.
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>FIELDS:
</span></span><span style=display:flex><span>  preferredDuringSchedulingIgnoredDuringExecution       &lt;<span style=color:#f92672>[]</span>PreferredSchedulingTerm&gt;
</span></span><span style=display:flex><span>    The scheduler will prefer to schedule pods to nodes that satisfy the
</span></span><span style=display:flex><span>    affinity expressions specified by this field, but it may choose a node that
</span></span><span style=display:flex><span>    violates one or more of the expressions. The node that is most preferred is
</span></span><span style=display:flex><span>    the one with the greatest sum of weights, i.e. <span style=color:#66d9ef>for</span> each node that meets all
</span></span><span style=display:flex><span>    of the scheduling requirements <span style=color:#f92672>(</span>resource request, requiredDuringScheduling
</span></span><span style=display:flex><span>    affinity expressions, etc.<span style=color:#f92672>)</span>, compute a sum by iterating through the elements
</span></span><span style=display:flex><span>    of this field and adding <span style=color:#e6db74>&#34;weight&#34;</span> to the sum <span style=color:#66d9ef>if</span> the node matches the
</span></span><span style=display:flex><span>    corresponding matchExpressions; the node<span style=color:#f92672>(</span>s<span style=color:#f92672>)</span> with the highest sum are the
</span></span><span style=display:flex><span>    most preferred.
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  requiredDuringSchedulingIgnoredDuringExecution        &lt;NodeSelector&gt;
</span></span><span style=display:flex><span>    If the affinity requirements specified by this field are not met at
</span></span><span style=display:flex><span>    scheduling time, the pod will not be scheduled onto the node. If the
</span></span><span style=display:flex><span>    affinity requirements specified by this field cease to be met at some point
</span></span><span style=display:flex><span>    during pod execution <span style=color:#f92672>(</span>e.g. due to an update<span style=color:#f92672>)</span>, the system may or may not try
</span></span><span style=display:flex><span>    to eventually evict the pod from its node.
</span></span></code></pre></div><p>#todo test this AND/OR condition</p><h3 id=example>Example<a hidden class=anchor aria-hidden=true href=#example>#</a></h3><p>#todo test if this actually works :D</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Pod</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span><span style=color:#f92672>name</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span><span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>env</span>: <span style=color:#ae81ff>test</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>	- <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>	  <span style=color:#f92672>image</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>	  <span style=color:#f92672>imagePullPolicy</span>: <span style=color:#ae81ff>IfNotPresent</span>
</span></span><span style=display:flex><span>	<span style=color:#f92672>nodeSelector</span>:
</span></span><span style=display:flex><span>		<span style=color:#f92672>matchFields</span>:
</span></span><span style=display:flex><span>			- <span style=color:#f92672>key</span>: <span style=color:#ae81ff>disktype</span>
</span></span><span style=display:flex><span>			  <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>			  <span style=color:#f92672>values</span>: [<span style=color:#ae81ff>ssd]</span>
</span></span></code></pre></div><h2 id=node-affinity>Node Affinity<a hidden class=anchor aria-hidden=true href=#node-affinity>#</a></h2><p>Use <em>node labels</em> to schedule pods on preferred nodes.</p><h3 id=property-2>Property<a hidden class=anchor aria-hidden=true href=#property-2>#</a></h3><p><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#affinity-v1-core>kubernetes-api/v1.24/#affinity-v1-core</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>podAffinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>podAntiAffinity</span>:
</span></span></code></pre></div><h3 id=rds-ide>RDS-IDE<a hidden class=anchor aria-hidden=true href=#rds-ide>#</a></h3><p>^^ Easier to remember version of <code>requiredDuringSchedulingIgnoredDuringExecution</code>. Type of [[#Node Affinity]].</p><p>Label specified under this property must be present on the node during scheduling. If it&rsquo;s subsequently removed, the pod still continues to run.</p><p>Scheduler will try to find a node that meets the expression. If no matching node is found, pod is <em>NOT scheduled</em> on any other node.</p><p>If the expression turns to false while the pod is running, it is still allowed to complete the execution.</p><h4 id=property-3>Property<a hidden class=anchor aria-hidden=true href=#property-3>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>	  <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>	    <span style=color:#f92672>nodeSelectorTerms</span>:
</span></span><span style=display:flex><span>		  - <span style=color:#ae81ff>nodeSelectorTerm1</span> <span style=color:#75715e># same as spec.nodeSelector</span>
</span></span><span style=display:flex><span>		  - <span style=color:#ae81ff>nodeSelectorTerm2</span>
</span></span></code></pre></div><p>Multiple <em>nodeSelectorTerm</em> can be specified, they are treated as <em>OR</em> statements</p><h3 id=pds-ide>PDS-IDE<a hidden class=anchor aria-hidden=true href=#pds-ide>#</a></h3><p>^^ Easier to remember version of <code>preferredDuringSchedulingIgnoredDuringExecution</code>. Type of [[#Node Affinity]]</p><p>[[#What is a Scheduler?|Scheduler]] will try to find a node that meets the expression, and has maximum aggregate weight. If no matching node is found, it <em>still schedules</em> the pod on a node.</p><p>If the expression turns to false while the pod is running, it is still allowed to complete the execution.</p><h4 id=property-4>Property<a hidden class=anchor aria-hidden=true href=#property-4>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>	  <span style=color:#f92672>preferredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>	    - <span style=color:#f92672>weight</span>: <span style=color:#ae81ff>0-100</span>
</span></span><span style=display:flex><span>	      <span style=color:#f92672>preference</span>: <span style=color:#ae81ff>nodeSelectorTerm</span> <span style=color:#75715e># same as spec.nodeSelector		</span>
</span></span></code></pre></div><h2 id=node-anti-affinity>Node Anti-Affinity<a hidden class=anchor aria-hidden=true href=#node-anti-affinity>#</a></h2><p>There is NO dedicated configuration field for this. Node anti-affinity is achieved by inverting the node affinity by using negation operators like <code>NotIn</code>, <code>DoesNotExist</code> in the specified <code>nodeSelectorTerm</code></p><h2 id=pod-affinity>Pod Affinity<a hidden class=anchor aria-hidden=true href=#pod-affinity>#</a></h2><p>Use running <em>pod labels</em> to schedule pods on preferred nodes. Like, deploy mysql pods on which ever nodes has postgresql pods running.</p><p>This is <strong>non-symmetric</strong> - no need to check if existing pods have specified any pod affinity before scheduling pods next to them that do specify a pod affinity</p><p><a href=https://github.com/kubernetes/design-proposals-archive/blob/main/scheduling/podaffinity.md#algorithm>algorithm</a> used by podaffinity</p><h3 id=property-5>Property<a hidden class=anchor aria-hidden=true href=#property-5>#</a></h3><p><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#affinity-v1-core>kubernetes-api/v1.24/#affinity-v1-core</a></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>nodeAffinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>podAffinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>podAntiAffinity</span>:
</span></span></code></pre></div><p>#todo <em>What&rsquo;s the difference between pod affinity and node affinity?</em>
#todo <em>What happens if all pods are deployed with a &lsquo;hard&rsquo; pod affinity, RDS-IDE?</em></p><h3 id=rds-ide-1>RDS-IDE<a hidden class=anchor aria-hidden=true href=#rds-ide-1>#</a></h3><p>^^ Easier to remember version of <code>requiredDuringSchedulingIgnoredDuringExecution</code>. Type of [[#Pod Affinity]].</p><p>Label specified under this property must be present during scheduling. If it&rsquo;s subsequently removed, the pod still continues to run.</p><p>[[#What is a Scheduler?|Scheduler]] will try to find a node that meets the expression. If NO matching node is found, pod is <em>NOT scheduled</em> on any other node.</p><p>If the expression turns to false while the pod is running, it is still allowed to complete the execution.</p><h4 id=property-6>Property<a hidden class=anchor aria-hidden=true href=#property-6>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>podAffinity</span>:
</span></span><span style=display:flex><span>	  <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>	    - <span style=color:#f92672>labelSelector</span>: <span style=color:#75715e># label query over pods</span>
</span></span><span style=display:flex><span>		    <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>		      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>		        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In, NotIn, Exist, DoesNotExist, Gt, Lt</span>
</span></span><span style=display:flex><span>			    <span style=color:#f92672>values</span>: [<span style=color:#ae81ff>string]</span> <span style=color:#75715e># array is replaced during strategic merge</span>
</span></span><span style=display:flex><span>			<span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>			  <span style=color:#f92672>key</span>: <span style=color:#ae81ff>value</span>
</span></span><span style=display:flex><span>		  <span style=color:#f92672>namespaces</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>		  <span style=color:#f92672>namespaceSelector</span>:
</span></span><span style=display:flex><span>		  	<span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>		      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>		        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In, NotIn, Exist, DoesNotExist, Gt, Lt</span>
</span></span><span style=display:flex><span>			    <span style=color:#f92672>values</span>: [<span style=color:#ae81ff>string]</span> <span style=color:#75715e># array is replaced during strategic merge</span>
</span></span><span style=display:flex><span>			<span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>			  <span style=color:#f92672>key</span>: <span style=color:#ae81ff>value</span>
</span></span><span style=display:flex><span>		  <span style=color:#f92672>topologyKey</span>: <span style=color:#ae81ff>string</span>
</span></span></code></pre></div><p>Multiple <em>nodeSelectorTerm</em> can be specified, they are treated as <em>OR</em> statements</p><p><em>topologyKey</em> is the key of a node label. It is used to select nodes belonging to a particular topology domain. For ex - Only launch pods in a specific AZ for access to a required volume. Or, only launch pods in a specific region.</p><h3 id=pds-ide-1>PDS-IDE<a hidden class=anchor aria-hidden=true href=#pds-ide-1>#</a></h3><p>^^ Easier to remember version of <code>preferredDuringSchedulingIgnoredDuringExecution</code>. Type of [[#Pod Affinity]].</p><p>[[#What is a Scheduler?|Scheduler]] will try to find a node that meets the expression, and has maximum aggregate weight. If NO matching node is found, it <em>still schedules</em> the pod on a node.</p><p>If the expression turns to false while the pod is running, it is still allowed to complete the execution.</p><h4 id=property-7>Property<a hidden class=anchor aria-hidden=true href=#property-7>#</a></h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>	<span style=color:#f92672>podAffinity</span>:
</span></span><span style=display:flex><span>	  <span style=color:#f92672>preferredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>	    - <span style=color:#f92672>weight</span>: <span style=color:#ae81ff>0-100</span>
</span></span><span style=display:flex><span>	      <span style=color:#f92672>podAffinityTerm</span>:
</span></span><span style=display:flex><span>	        <span style=color:#f92672>labelSelector</span>: <span style=color:#75715e># label query over pods</span>
</span></span><span style=display:flex><span>		      <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>		        - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>		          <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In, NotIn, Exist, DoesNotExist, Gt, Lt</span>
</span></span><span style=display:flex><span>			      <span style=color:#f92672>values</span>: [<span style=color:#ae81ff>string]</span> <span style=color:#75715e># array is replaced during strategic merge</span>
</span></span><span style=display:flex><span>			  <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>			    <span style=color:#f92672>key</span>: <span style=color:#ae81ff>value</span>
</span></span><span style=display:flex><span>		    <span style=color:#f92672>namespaces</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>		    <span style=color:#f92672>namespaceSelector</span>:
</span></span><span style=display:flex><span>		  	  <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>		        - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>string</span>
</span></span><span style=display:flex><span>		          <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In, NotIn, Exist, DoesNotExist, Gt, Lt</span>
</span></span><span style=display:flex><span>				  <span style=color:#f92672>values</span>: [<span style=color:#ae81ff>string]</span> <span style=color:#75715e># array is replaced during strategic merge</span>
</span></span><span style=display:flex><span>			  <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>				<span style=color:#f92672>key</span>: <span style=color:#ae81ff>value</span>
</span></span><span style=display:flex><span>		    <span style=color:#f92672>topologyKey</span>: <span style=color:#ae81ff>string	</span>
</span></span></code></pre></div><h5 id=warning>Warning!<a hidden class=anchor aria-hidden=true href=#warning>#</a></h5><p><code>labelSelector: null</code> can cause NO pods to match the expression, and make a pod unschedulable!</p><h2 id=pod-anti-affinity>Pod Anti-Affinity<a hidden class=anchor aria-hidden=true href=#pod-anti-affinity>#</a></h2><p>There is no dedicated configuration field for this. Pod anti-affinity is achieved by inverting the pod affinity by using negation operators like <code>NotIn</code>, <code>DoesNotExist</code> in the specified <code>podAffinityTerm</code></p><p>This is <strong>symmetric</strong> - even if a pod doesn&rsquo;t specify an anti-affinity rule, it is still checked so as not to violate the anti-affinity rule specified by an already running pod.</p><h2 id=taints-and-tolerations>Taints and Tolerations<a hidden class=anchor aria-hidden=true href=#taints-and-tolerations>#</a></h2><ul><li><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/>taint-and-toleration</a></li></ul><h2 id=autoscaling>Autoscaling<a hidden class=anchor aria-hidden=true href=#autoscaling>#</a></h2><h3 id=karpenter>Karpenter<a hidden class=anchor aria-hidden=true href=#karpenter>#</a></h3><p><a href=https://karpenter.sh>https://karpenter.sh</a></p><p><img loading=lazy src=https://karpenter.sh/nodeclaims.png alt=karpenter></p><ul><li>Karpenter consolidation policies - &ldquo;whenempty&rdquo;</li><li>Pod Disruption Budgets</li><li>Karpenter can switch instance types to rightsize the nodes if pods aren&rsquo;t using the node&rsquo;s resources - depends on consolidation policies</li><li>Karpenter AZ awarness - How does it work with EBS across different AZ? <a href=https://aws.amazon.com/blogs/containers/scaling-kubernetes-with-karpenter-advanced-scheduling-with-pod-affinity-and-volume-topology-awareness/>aws blogs/volume topolog -awareness</a></li><li>Karpenter can sometimes overestimate node sizes (daemonset overheads) - <a href=https://github.com/kubernetes-sigs/karpenter/issues/715>karpenter/issues/715</a></li></ul><h3 id=cluster-auto-scaler>Cluster Auto-scaler<a hidden class=anchor aria-hidden=true href=#cluster-auto-scaler>#</a></h3><ul><li><a href=https://kubernetes.io/docs/concepts/cluster-administration/cluster-autoscaling/>cluster-autoscaling</a></li><li><a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>cluster-autoscaler</a></li></ul><h3 id=horizontal-pod-autoscaler>Horizontal Pod Autoscaler<a hidden class=anchor aria-hidden=true href=#horizontal-pod-autoscaler>#</a></h3><ul><li><a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/>HPA</a></li></ul><h3 id=vertical-pod-autoscaler>Vertical Pod Autoscaler<a hidden class=anchor aria-hidden=true href=#vertical-pod-autoscaler>#</a></h3><ul><li><a href=https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md>VPA</a></li></ul><h3 id=event-driven-autoscaling>Event-driven Autoscaling<a hidden class=anchor aria-hidden=true href=#event-driven-autoscaling>#</a></h3><ul><li><a href=https://keda.sh/>KEDA</a></li></ul><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2></div><footer class=post-footer><hr><div class=align-center><div class=slimlist-entry><h2>Topics</h2></div><ul class=post-tags><div class=slimlist-entry><li class=post-tags><a href=https://abiydv.github.io/topics/k8s/>k8s</a></li><li class=post-tags><a href=https://abiydv.github.io/topics/stage-incubating/>stage/incubating</a></li><li class=post-tags><a href=https://abiydv.github.io/topics/containers/>containers</a></li></div></ul></div></footer><script src=https://utteranc.es/client.js repo=abiydv/abiydv.github.io issue-term=title label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2019-2025 <a href=https://abiydv.github.io/>@abiydv</a> / </span><span>Published 4.4.25 /
</span><span>Thanks <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a>, <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>